# running_llm_on_cpu_quantization
This project demonstrates a proof of concept for quantization by running the LLaMA model on a standard CPU-based machine
